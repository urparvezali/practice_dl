{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: data/cifar10.tgz\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets.utils import download_url\n",
    "\n",
    "data_url = \"https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz\"\n",
    "download_url(data_url, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import index\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "with tarfile.open(\"data/cifar10.tgz\",'r') as tr:\n",
    "\tdirs = os.listdir(\"data\")\n",
    "\tif not dirs.index('cifar10'):\n",
    "\t\ttr.extractall(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "combined_transforms = transforms.Compose(\n",
    "\ttransforms=[\n",
    "\t\ttransforms.ToTensor(),\n",
    "\t]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000, 10)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import randint\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "train_dataset = ImageFolder(\n",
    "\troot=\"data/cifar10/train\",\n",
    "\ttransform=combined_transforms\n",
    ")\n",
    "test_dataset = ImageFolder(\n",
    "\troot=\"data/cifar10/test\",\n",
    "\ttransform=combined_transforms\n",
    ")\n",
    "img, lbl = train_dataset[randint(0, len(train_dataset), size=(1,)).item()]\n",
    "len(train_dataset), len(test_dataset),len(train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1563, 313)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "train_itr = DataLoader(\n",
    "\tdataset=train_dataset,\n",
    "\tbatch_size=batch_size,\n",
    "\tshuffle=True,\n",
    ")\n",
    "test_itr = DataLoader(\n",
    "\tdataset=test_dataset,\n",
    "\tbatch_size=batch_size,\n",
    "\tshuffle=True,\n",
    ")\n",
    "len(train_itr), len(test_itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, randn\n",
    "import torch\n",
    "class ClassifyObjects(nn.Module):\n",
    "\tdef __init__(\n",
    "\t\t\tself,\n",
    "\t\t\tinput_channels:int=3,\n",
    "\t\t\toutput_channels:int=10,\n",
    "\t\t\thidden_units:int=16,\n",
    "\t\t\tbatch_size:int=32,\n",
    "\t):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself.input_channels = input_channels\n",
    "\t\tself.output_channels = output_channels\n",
    "\t\tself.hidden_units = hidden_units\n",
    "\t\tself.batch_size = batch_size\n",
    "\n",
    "\t\tself.input_stack = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(\n",
    "\t\t\t\tin_channels=self.input_channels,\n",
    "\t\t\t\tout_channels=self.hidden_units,\n",
    "\t\t\t\tkernel_size=2,\n",
    "\t\t\t\tstride=1,\n",
    "\t\t\t\tpadding=0,\n",
    "\t\t\t),\n",
    "\t\t\tnn.MaxPool2d(\n",
    "\t\t\t\tkernel_size=2,\n",
    "\t\t\t),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t)\n",
    "\t\tself.hidden_stack0 = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(\n",
    "\t\t\t\tin_channels=self.hidden_units,\n",
    "\t\t\t\tout_channels=self.hidden_units,\n",
    "\t\t\t\tkernel_size=2,\n",
    "\t\t\t\tstride=1,\n",
    "\t\t\t\tpadding=0,\n",
    "\t\t\t),\n",
    "\t\t\tnn.MaxPool2d(\n",
    "\t\t\t\tkernel_size=2,\n",
    "\t\t\t),\n",
    "\t\t\tnn.Conv2d(\n",
    "\t\t\t\tin_channels=self.hidden_units,\n",
    "\t\t\t\tout_channels=self.hidden_units,\n",
    "\t\t\t\tkernel_size=2,\n",
    "\t\t\t\tstride=1,\n",
    "\t\t\t\tpadding=0,\n",
    "\t\t\t),\n",
    "\t\t\tnn.MaxPool2d(\n",
    "\t\t\t\tkernel_size=2,\n",
    "\t\t\t),\n",
    "\t\t)\n",
    "\t\tself.output_stack = nn.Sequential(\n",
    "\t\t\tnn.Flatten(),\n",
    "\t\t\tnn.Linear(\n",
    "\t\t\t\tin_features=self.batch_size*3*3,\n",
    "\t\t\t\tout_features=output_channels*2,\n",
    "\t\t\t),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(\n",
    "\t\t\t\tin_features=output_channels*2,\n",
    "\t\t\t\tout_features=output_channels,\n",
    "\t\t\t)\n",
    "\t\t)\n",
    "\tdef forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "\t\tx = self.input_stack(x)\n",
    "\t\t# print(x.shape)\n",
    "\t\tx = self.hidden_stack0(x)\n",
    "\t\t# print(x.shape)\n",
    "\t\tx = self.output_stack(x)\n",
    "\t\treturn x\n",
    "\tdef accuracy(self, preds: torch.Tensor, real: torch.Tensor):\n",
    "\t\treturn torch.eq(preds.argmax(dim=1), real).sum().item()/self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "ClassifyObjects                          --\n",
       "├─Sequential: 1-1                        --\n",
       "│    └─Conv2d: 2-1                       208\n",
       "│    └─MaxPool2d: 2-2                    --\n",
       "│    └─ReLU: 2-3                         --\n",
       "├─Sequential: 1-2                        --\n",
       "│    └─Conv2d: 2-4                       1,040\n",
       "│    └─MaxPool2d: 2-5                    --\n",
       "│    └─Conv2d: 2-6                       1,040\n",
       "│    └─MaxPool2d: 2-7                    --\n",
       "├─Sequential: 1-3                        --\n",
       "│    └─Flatten: 2-8                      --\n",
       "│    └─Linear: 2-9                       2,900\n",
       "│    └─ReLU: 2-10                        --\n",
       "│    └─Linear: 2-11                      210\n",
       "=================================================================\n",
       "Total params: 5,398\n",
       "Trainable params: 5,398\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "mdl = ClassifyObjects(\n",
    "\tinput_channels=3,\n",
    "\toutput_channels=10,\n",
    "\thidden_units=16,\n",
    "\tbatch_size=16,\n",
    ")\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(\n",
    "\tparams=mdl.parameters(),\n",
    "\tlr=0.01,\n",
    ")\n",
    "summary(mdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 acc:0.00 loss:2.297070026397705\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\tmdl.train()\n",
    "\tfor batch, (x, y) in enumerate(train_itr):\n",
    "\t\tpreds = mdl(x)\n",
    "\t\tloss = loss_fn(preds, y)\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\tmdl.eval()\n",
    "\twith torch.inference_mode():\n",
    "\t\ttacc, tloss = 0, 0\n",
    "\t\tfor tx, ty in test_itr:\n",
    "\t\t\ttpreds = mdl(tx)\n",
    "\t\t\ttloss+=loss_fn(tpreds, ty)\n",
    "\t\t\tmdl.accuracy(tpreds, ty)\n",
    "\t\ttacc/=len(test_itr)\n",
    "\t\ttloss/=len(test_itr)\n",
    "\tprint(f\"epoch:{epoch} acc:{tacc*100:.2f} loss:{tloss}\")\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
